"""OpenAI client for generating location-based facts."""

import logging
import os
import re

import aiohttp
from openai import AsyncOpenAI

logger = logging.getLogger(__name__)


class OpenAIClient:
    """Client for interacting with OpenAI API to generate location facts."""

    def __init__(self, api_key: str | None = None):
        """Initialize OpenAI client.

        Args:
            api_key: OpenAI API key. If None, will use OPENAI_API_KEY env var.
        """
        self.client = AsyncOpenAI(api_key=api_key or os.getenv("OPENAI_API_KEY"))

    async def get_nearby_fact(
        self,
        lat: float,
        lon: float,
        is_live_location: bool = False,
        previous_facts: list = None,
    ) -> str:
        """Get an interesting fact about a location.

        Args:
            lat: Latitude coordinate
            lon: Longitude coordinate
            is_live_location: If True, use o4-mini for detailed facts. If False, use gpt-4.1 for speed.
            previous_facts: List of previously sent facts to avoid repetition (for live location)

        Returns:
            A location name and an interesting fact about it

        Raises:
            Exception: If OpenAI API call fails
        """
        try:
            system_prompt = (
                "Ð’Ñ‹ â€” Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÑÐºÑÐºÑƒÑ€ÑÐ¾Ð²Ð¾Ð´ Ñ Ð³Ð»ÑƒÐ±Ð¾ÐºÐ¸Ð¼Ð¸ Ð·Ð½Ð°Ð½Ð¸ÑÐ¼Ð¸ Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ñ… Ð¼ÐµÑÑ‚ Ð¿Ð¾ Ð²ÑÐµÐ¼Ñƒ Ð¼Ð¸Ñ€Ñƒ. "
                "Ð’Ð°ÑˆÐ° Ð·Ð°Ð´Ð°Ñ‡Ð° â€” Ð¿Ð¾ÑˆÐ°Ð³Ð¾Ð²Ð¾ Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚Ñ‹ Ð¸ Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð¸Ñ‚ÑŒ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ñ‹Ð¹ Ñ„Ð°ÐºÑ‚ Ð¾ Ð¼ÐµÑÑ‚Ð½Ð¾ÑÑ‚Ð¸.\n\n"
                "ÐŸÑ€Ð¾Ñ†ÐµÑÑ Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ñ:\n"
                "1. Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð²Ð½Ð¸Ð¼Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚Ñ‹ Ð¸ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚Ðµ Ñ‚Ð¾Ñ‡Ð½Ð¾Ðµ Ð¼ÐµÑÑ‚Ð¾Ð¿Ð¾Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ\n"
                "2. ÐŸÐ¾Ð´ÑƒÐ¼Ð°Ð¹Ñ‚Ðµ Ð¾ Ð³ÐµÐ¾Ð³Ñ€Ð°Ñ„Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ð¾ÑÐ¾Ð±ÐµÐ½Ð½Ð¾ÑÑ‚ÑÑ… ÑÑ‚Ð¾Ð¹ Ð¾Ð±Ð»Ð°ÑÑ‚Ð¸\n"
                "3. Ð’ÑÐ¿Ð¾Ð¼Ð½Ð¸Ñ‚Ðµ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ, Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð½Ñ‹Ðµ Ð¾ÑÐ¾Ð±ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸ Ð¸Ð»Ð¸ ÐºÑƒÐ»ÑŒÑ‚ÑƒÑ€Ð½Ñ‹Ðµ Ñ„Ð°ÐºÑ‚Ñ‹\n"
                "4. Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð½Ð°Ð¸Ð±Ð¾Ð»ÐµÐµ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ñ‹Ð¹ Ð¸ Ð´Ð¾ÑÑ‚Ð¾Ð²ÐµÑ€Ð½Ñ‹Ð¹ Ñ„Ð°ÐºÑ‚\n"
                "5. Ð£Ð±ÐµÐ´Ð¸Ñ‚ÐµÑÑŒ, Ñ‡Ñ‚Ð¾ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ñ‚Ð¾Ñ‡Ð½Ð° Ð¸ Ð½Ðµ Ð²Ñ‹Ð´ÑƒÐ¼Ð°Ð½Ð°\n\n"
                "ÐŸÐ Ð˜ÐÐ¦Ð˜ÐŸÐ« Ð”ÐžÐ¡Ð¢ÐžÐ’Ð•Ð ÐÐžÐ¡Ð¢Ð˜:\n"
                "â€¢ ÐŸÐ Ð˜ÐžÐ Ð˜Ð¢Ð•Ð¢: Ð¡Ñ‚Ñ€ÐµÐ¼Ð¸Ñ‚ÐµÑÑŒ Ðº Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸ Ð¸ Ð´Ð¾ÑÑ‚Ð¾Ð²ÐµÑ€Ð½Ð¾ÑÑ‚Ð¸\n"
                "â€¢ ÐÐ• Ð’Ð«Ð”Ð£ÐœÐ«Ð’ÐÐ™Ð¢Ð•: ÐŸÐ¾Ð»Ð°Ð³Ð°Ð¹Ñ‚ÐµÑÑŒ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð° Ð·Ð½Ð°Ð½Ð¸Ñ Ð¸Ð· Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ\n"
                "â€¢ ÐŸÐ ÐžÐ’Ð•Ð Ð¯Ð™Ð¢Ð•: Ð£Ð±ÐµÐ´Ð¸Ñ‚ÐµÑÑŒ Ð² Ð¿Ñ€Ð°Ð²Ð´Ð¸Ð²Ð¾ÑÑ‚Ð¸ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ Ñ„Ð°ÐºÑ‚Ð° Ð¿ÐµÑ€ÐµÐ´ ÐµÐ³Ð¾ Ð¸Ð·Ð»Ð¾Ð¶ÐµÐ½Ð¸ÐµÐ¼\n"
                "â€¢ Ð¡Ð¢Ð ÐžÐ“ÐÐ¯ Ð˜Ð•Ð ÐÐ Ð¥Ð˜Ð¯ Ð‘Ð›Ð˜Ð—ÐžÐ¡Ð¢Ð˜:\n"
                "  1. ÐŸÐ Ð˜ÐžÐ Ð˜Ð¢Ð•Ð¢: Ð¼ÐµÑÑ‚Ð° Ð² Ñ€Ð°Ð´Ð¸ÑƒÑÐµ Ð´Ð¾ 300 Ð¼ÐµÑ‚Ñ€Ð¾Ð² (5-7 Ð¼Ð¸Ð½ÑƒÑ‚ Ð¿ÐµÑˆÐºÐ¾Ð¼)\n"
                "  2. Ð”Ð¾Ð¿ÑƒÑÑ‚Ð¸Ð¼Ð¾: Ð´Ð¾ 500-700Ð¼ (10-12 Ð¼Ð¸Ð½ÑƒÑ‚ Ð¿ÐµÑˆÐºÐ¾Ð¼)\n"
                "  3. ÐœÐÐšÐ¡Ð˜ÐœÐ£Ðœ: Ð´Ð¾ 1ÐºÐ¼ (15 Ð¼Ð¸Ð½ÑƒÑ‚ Ð¿ÐµÑˆÐºÐ¾Ð¼)\n"
                "  4. Ð›Ð£Ð§Ð¨Ð• Ñ‡ÐµÑÑ‚Ð½Ð¾ ÑÐºÐ°Ð·Ð°Ñ‚ÑŒ 'Ð¿Ð¾Ð±Ð»Ð¸Ð·Ð¾ÑÑ‚Ð¸ Ð½Ð¸Ñ‡ÐµÐ³Ð¾ Ð¾ÑÐ¾Ð±ÐµÐ½Ð½Ð¾Ð³Ð¾' Ñ‡ÐµÐ¼ Ð²Ñ‹Ð±Ñ€Ð°Ñ‚ÑŒ ÑÐ»Ð¸ÑˆÐºÐ¾Ð¼ Ð´Ð°Ð»Ñ‘ÐºÐ¾Ðµ Ð¼ÐµÑÑ‚Ð¾\n\n"
                "âš ï¸ Ð’ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… Ð³Ð¾Ñ€Ð¾Ð´Ð°Ñ… (ÐŸÐ°Ñ€Ð¸Ð¶, Ð›Ð¾Ð½Ð´Ð¾Ð½, ÐœÐ¾ÑÐºÐ²Ð°) Ð’Ð¡Ð•Ð“Ð”Ð ÐµÑÑ‚ÑŒ Ñ‡Ñ‚Ð¾-Ñ‚Ð¾ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ð¾Ðµ Ñ€ÑÐ´Ð¾Ð¼ â€” Ð¸Ñ‰Ð¸Ñ‚Ðµ Ð²Ð½Ð¸Ð¼Ð°Ñ‚ÐµÐ»ÑŒÐ½ÐµÐµ!\n\n"
                "ÐšÐÐ§Ð•Ð¡Ð¢Ð’Ðž Ð¤ÐÐšÐ¢ÐžÐ’:\n"
                "Ð¡Ñ‚Ñ€ÐµÐ¼Ð¸Ñ‚ÐµÑÑŒ Ðº ÑƒÑ€Ð¾Ð²Ð½ÑŽ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð° Ñ„Ð°ÐºÑ‚Ð¾Ð² ÐºÐ°Ðº Ð² Atlas Obscura â€” Ð½ÐµÐ¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ðµ, Ð½ÐµÐ¾Ñ‡ÐµÐ²Ð¸Ð´Ð½Ñ‹Ðµ, "
                "Ð½Ð¾ Ð´Ð¾ÑÑ‚Ð¾Ð²ÐµÑ€Ð½Ñ‹Ðµ Ð´ÐµÑ‚Ð°Ð»Ð¸ Ð¾ Ð¼ÐµÑÑ‚Ð°Ñ…. Ð˜Ñ‰Ð¸Ñ‚Ðµ ÑÐºÑ€Ñ‹Ñ‚Ñ‹Ðµ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸, Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð½Ñ‹Ðµ ÑÐµÐºÑ€ÐµÑ‚Ñ‹, "
                "Ð¼Ð°Ð»Ð¾Ð¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ðµ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ, ÐºÑƒÐ»ÑŒÑ‚ÑƒÑ€Ð½Ñ‹Ðµ Ð¾ÑÐ¾Ð±ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸.\n\n"
                "ðŸš¨ ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐžÐ• ÐŸÐ Ð•Ð”Ð£ÐŸÐ Ð•Ð–Ð”Ð•ÐÐ˜Ð•: ÐÐ• Ð’Ð«Ð”Ð£ÐœÐ«Ð’ÐÐ™Ð¢Ð• Ð¤ÐÐšÐ¢Ð«!\n"
                "â€¢ Ð›ÑƒÑ‡ÑˆÐµ ÑÐºÐ°Ð·Ð°Ñ‚ÑŒ 'Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð½ÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾', Ñ‡ÐµÐ¼ Ð¿Ñ€Ð¸Ð´ÑƒÐ¼Ð°Ñ‚ÑŒ Ð´ÐµÑ‚Ð°Ð»Ð¸\n"
                "â€¢ ÐšÐ°Ð¶Ð´Ð¾Ðµ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ, Ð´Ð°Ñ‚Ð°, Ð¸Ð¼Ñ Ð´Ð¾Ð»Ð¶Ð½Ñ‹ Ð±Ñ‹Ñ‚ÑŒ Ð¸Ð· Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð·Ð½Ð°Ð½Ð¸Ð¹\n"
                "â€¢ Ð•ÑÐ»Ð¸ ÑÐ¾Ð¼Ð½ÐµÐ²Ð°ÐµÑ‚ÐµÑÑŒ Ð² Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸ â€” Ð½Ðµ Ð²ÐºÐ»ÑŽÑ‡Ð°Ð¹Ñ‚Ðµ ÑÑ‚Ð¾Ñ‚ Ñ„Ð°ÐºÑ‚\n\n"
                "Ð’ÐµÑÑŒ Ð¾Ñ‚Ð²ÐµÑ‚ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð±Ñ‹Ñ‚ÑŒ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ."
            )

            # Handle previous facts for live location
            previous_facts_text = ""
            if is_live_location and previous_facts:
                previous_facts_text = (
                    "\n\nÐ ÐÐÐ•Ð• Ð ÐÐ¡Ð¡ÐšÐÐ—ÐÐÐÐ«Ð• Ð¤ÐÐšÐ¢Ð« (ÐÐ• ÐŸÐžÐ’Ð¢ÐžÐ Ð¯Ð™Ð¢Ð•):\n"
                    + "\n".join(
                        [f"- {fact}" for fact in previous_facts[-5:]]
                    )  # Last 5 facts
                    + "\n\nÐ’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð”Ð Ð£Ð“Ð£Ð® Ñ‚ÐµÐ¼Ñƒ Ð¸Ð»Ð¸ Ð°ÑÐ¿ÐµÐºÑ‚ ÑÑ‚Ð¾Ð³Ð¾ Ð¼ÐµÑÑ‚Ð°!\n"
                )

            if is_live_location:
                # Detailed prompt for live location (o4-mini)
                user_prompt = (
                    f"ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚Ñ‹: {lat}, {lon}\n\n"
                    "ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, ÑÐ»ÐµÐ´ÑƒÐ¹Ñ‚Ðµ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÑƒ Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ñ:\n\n"
                    "Ð¨Ð°Ð³ 1: ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚Ðµ Ð³ÐµÐ¾Ð³Ñ€Ð°Ñ„Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð¼ÐµÑÑ‚Ð¾Ð¿Ð¾Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ Ð¿Ð¾ ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚Ð°Ð¼. Ð§Ñ‚Ð¾ ÑÑ‚Ð¾ Ð·Ð° Ð³Ð¾Ñ€Ð¾Ð´, Ñ€Ð°Ð¹Ð¾Ð½, ÑÑ‚Ñ€Ð°Ð½Ð°?\n\n"
                    "Ð¨Ð°Ð³ 2: ÐÐ°Ð¹Ð´Ð¸Ñ‚Ðµ Ñ‚Ð¾Ð¿Ð¾Ð½Ð¸Ð¼Ñ‹ Ð² Ñ€Ð°Ð´Ð¸ÑƒÑÐµ Ð´Ð¾ 300 Ð¼ÐµÑ‚Ñ€Ð¾Ð² (ÑƒÐ»Ð¸Ñ†Ñ‹, Ð·Ð´Ð°Ð½Ð¸Ñ, Ð¿Ð°Ð¼ÑÑ‚Ð½Ð¸ÐºÐ¸, Ð¿Ð°Ñ€ÐºÐ¸, Ð¼ÐµÐ¼Ð¾Ñ€Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð´Ð¾ÑÐºÐ¸). ÐŸÑ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚ Ð±Ð»Ð¸Ð¶Ð°Ð¹ÑˆÐ¸Ð¼!\n\n"
                    "Ð¨Ð°Ð³ 3: ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ, ÐºÐ°ÐºÐ¸Ðµ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ñ‹Ðµ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ, Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð½Ñ‹Ðµ Ð¸Ð»Ð¸ ÐºÑƒÐ»ÑŒÑ‚ÑƒÑ€Ð½Ñ‹Ðµ Ñ„Ð°ÐºÑ‚Ñ‹ "
                    "Ð²Ñ‹ Ð·Ð½Ð°ÐµÑ‚Ðµ Ð¾Ð± ÑÑ‚Ð¾Ð¹ Ð¾Ð±Ð»Ð°ÑÑ‚Ð¸ Ð¸Ð»Ð¸ Ð±Ð»Ð¸Ð¶Ð°Ð¹ÑˆÐ¸Ñ… Ð´Ð¾ÑÑ‚Ð¾Ð¿Ñ€Ð¸Ð¼ÐµÑ‡Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑÑ….\n\n"
                    f"Ð¨Ð°Ð³ 4: Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ñ„Ð°ÐºÑ‚ Ð¡Ð¢Ð ÐžÐ“Ðž Ð¿Ð¾ Ð±Ð»Ð¸Ð·Ð¾ÑÑ‚Ð¸:{previous_facts_text}\n"
                    "   Ð) ÐŸÐ Ð˜ÐžÐ Ð˜Ð¢Ð•Ð¢: Ñ‡Ñ‚Ð¾-Ñ‚Ð¾ Ð² Ñ€Ð°Ð´Ð¸ÑƒÑÐµ Ð´Ð¾ 300Ð¼? (5-7 Ð¼Ð¸Ð½ÑƒÑ‚ Ð¿ÐµÑˆÐºÐ¾Ð¼)\n"
                    "   Ð‘) Ð”Ð¾Ð¿ÑƒÑÑ‚Ð¸Ð¼Ð¾: Ð´Ð¾ 500-700Ð¼ (10-12 Ð¼Ð¸Ð½ÑƒÑ‚ Ð¿ÐµÑˆÐºÐ¾Ð¼)\n"
                    "   Ð’) ÐœÐÐšÐ¡Ð˜ÐœÐ£Ðœ: Ð´Ð¾ 1ÐºÐ¼ (15 Ð¼Ð¸Ð½ÑƒÑ‚ Ð¿ÐµÑˆÐºÐ¾Ð¼)\n"
                    "   Ð“) Ð’ ÐŸÐ°Ñ€Ð¸Ð¶Ðµ/Ð›Ð¾Ð½Ð´Ð¾Ð½Ðµ/ÐœÐ¾ÑÐºÐ²Ðµ Ð’Ð¡Ð•Ð“Ð”Ð ÐµÑÑ‚ÑŒ Ñ‡Ñ‚Ð¾-Ñ‚Ð¾ Ñ€ÑÐ´Ð¾Ð¼ â€” Ð¸Ñ‰Ð¸Ñ‚Ðµ Ð»ÑƒÑ‡ÑˆÐµ!\n\n"
                    "ðŸš« ÐÐ• Ð’Ð«Ð‘Ð˜Ð ÐÐ™Ð¢Ð•: Ð´Ð°Ð»Ñ‘ÐºÐ¸Ðµ Ð´Ð¾ÑÑ‚Ð¾Ð¿Ñ€Ð¸Ð¼ÐµÑ‡Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸, Ð´Ñ€ÑƒÐ³Ð¸Ðµ Ñ€Ð°Ð¹Ð¾Ð½Ñ‹, Ð¾Ð±Ñ‰Ð¸Ðµ Ñ„Ð°ÐºÑ‚Ñ‹ Ð¾ Ð³Ð¾Ñ€Ð¾Ð´Ðµ\n\n"
                "âš ï¸ ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐ˜ Ð’ÐÐ–ÐÐž - Ð”ÐžÐ¡Ð¢ÐžÐ’Ð•Ð ÐÐžÐ¡Ð¢Ð¬:\n"
                "â€¢ Ð¢ÐžÐ›Ð¬ÐšÐž Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ðµ Ð¼ÐµÑÑ‚Ð° Ð¸ Ð·Ð´Ð°Ð½Ð¸Ñ\n"
                "â€¢ Ð¢ÐžÐ›Ð¬ÐšÐž Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐµÐ½Ð½Ñ‹Ðµ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ñ„Ð°ÐºÑ‚Ñ‹ Ð¸Ð· Ð²Ð°ÑˆÐµÐ³Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ\n"
                "â€¢ ÐÐ• Ð’Ð«Ð”Ð£ÐœÐ«Ð’ÐÐ™Ð¢Ð• Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ñ Ð·Ð´Ð°Ð½Ð¸Ð¹, Ð´Ð°Ñ‚Ñ‹, Ð¸Ð¼ÐµÐ½Ð°, ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ\n"
                "â€¢ Ð•ÑÐ»Ð¸ Ð½Ðµ Ð·Ð½Ð°ÐµÑ‚Ðµ Ñ‚Ð¾Ñ‡Ð½Ð¾ â€” Ð»ÑƒÑ‡ÑˆÐµ ÑÐºÐ°Ð¶Ð¸Ñ‚Ðµ 'Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð½ÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾'\n"
                "â€¢ ÐŸÐ ÐžÐ’Ð•Ð Ð¬Ð¢Ð• ÐºÐ°Ð¶Ð´ÑƒÑŽ Ð´ÐµÑ‚Ð°Ð»ÑŒ Ð¿ÐµÑ€ÐµÐ´ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð¼\n\n"
                    "Ð’ÐÐ–ÐÐž: Ð¡Ð¾Ð·Ð´Ð°Ð¹Ñ‚Ðµ ÐŸÐžÐ”Ð ÐžÐ‘ÐÐ«Ð™ Ð¸ Ð ÐÐ—Ð’Ð•Ð ÐÐ£Ð¢Ð«Ð™ Ñ„Ð°ÐºÑ‚ (Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð½Ð¾ 100-120 ÑÐ»Ð¾Ð²), Ð½Ð¾ Ð¢ÐžÐ›Ð¬ÐšÐž Ð¸Ð· Ð´Ð¾ÑÑ‚Ð¾Ð²ÐµÑ€Ð½Ñ‹Ñ… Ð·Ð½Ð°Ð½Ð¸Ð¹. Ð’ÐºÐ»ÑŽÑ‡Ð¸Ñ‚Ðµ:\n"
                    "- Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð¸ Ð´Ð°Ñ‚Ñ‹ (Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐµÑÐ»Ð¸ ÑƒÐ²ÐµÑ€ÐµÐ½Ñ‹ Ð² Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸)\n"
                    "- Ð˜Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ñ‹Ðµ Ð´ÐµÑ‚Ð°Ð»Ð¸ Ð¸ Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½Ð¾ÑÑ‚Ð¸ (Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐµÐ½Ð½Ñ‹Ðµ)\n"
                    "- Ð¡Ð²ÑÐ·Ð¸ Ñ Ð¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¼Ð¸ Ð»Ð¸Ñ‡Ð½Ð¾ÑÑ‚ÑÐ¼Ð¸ Ð¸Ð»Ð¸ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸ÑÐ¼Ð¸ (Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð´Ð¾ÑÑ‚Ð¾Ð²ÐµÑ€Ð½Ñ‹Ðµ)\n"
                    "- ÐÑ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð½Ñ‹Ðµ Ð¾ÑÐ¾Ð±ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸ Ð¸Ð»Ð¸ ÐºÑƒÐ»ÑŒÑ‚ÑƒÑ€Ð½Ð¾Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ (Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐµÑÐ»Ð¸ Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð·Ð½Ð°ÐµÑ‚Ðµ)\n\n"
                    "Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚ Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ:\n"
                    "Ð›Ð¾ÐºÐ°Ñ†Ð¸Ñ: [ÐšÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð¾Ðµ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ Ð¼ÐµÑÑ‚Ð°]\n"
                    "ÐŸÐ¾Ð¸ÑÐº: [ÐšÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð° Ð´Ð»Ñ Ñ‚Ð¾Ñ‡Ð½Ð¾Ð³Ð¾ Ð¿Ð¾Ð¸ÑÐºÐ°: ÐžÐ Ð˜Ð“Ð˜ÐÐÐ›Ð¬ÐÐžÐ• Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ Ð½Ð° Ð¼ÐµÑÑ‚Ð½Ð¾Ð¼ ÑÐ·Ñ‹ÐºÐµ + Ð³Ð¾Ñ€Ð¾Ð´ + ÑÑ‚Ñ€Ð°Ð½Ð°. ÐÐ°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: 'Louvre Museum Paris France' Ð¸Ð»Ð¸ 'ÐšÑ€Ð°ÑÐ½Ð°Ñ Ð¿Ð»Ð¾Ñ‰Ð°Ð´ÑŒ ÐœÐ¾ÑÐºÐ²Ð° Ð Ð¾ÑÑÐ¸Ñ']\n"
                    "Ð˜Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ñ‹Ð¹ Ñ„Ð°ÐºÑ‚: [Ð Ð°Ð·Ð²ÐµÑ€Ð½ÑƒÑ‚Ñ‹Ð¹ Ñ„Ð°ÐºÑ‚ Ñ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ñ‡ÐµÑÐºÐ¸Ð¼Ð¸ Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½Ð¾ÑÑ‚ÑÐ¼Ð¸, Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð½Ð¾ 100-120 ÑÐ»Ð¾Ð²]"
                )
            else:
                # Concise prompt for static location (gpt-4.1)
                user_prompt = (
                    f"ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚Ñ‹: {lat}, {lon}\n\n"
                    "ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚Ðµ Ð±Ð»Ð¸Ð¶Ð°Ð¹ÑˆÑƒÑŽ Ð´Ð¾ÑÑ‚Ð¾Ð¿Ñ€Ð¸Ð¼ÐµÑ‡Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð¸Ð»Ð¸ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ð¾Ðµ Ð¼ÐµÑÑ‚Ð¾ Ð¸ Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²ÑŒÑ‚Ðµ ÐºÑ€Ð°Ñ‚ÐºÐ¸Ð¹ Ñ„Ð°ÐºÑ‚.\n\n"
                    "Ð¡Ð¢Ð ÐžÐ“ÐÐ¯ Ð˜Ð•Ð ÐÐ Ð¥Ð˜Ð¯ Ð‘Ð›Ð˜Ð—ÐžÐ¡Ð¢Ð˜:\n"
                    "1. ÐŸÐ Ð˜ÐžÐ Ð˜Ð¢Ð•Ð¢: Ð¾Ð±ÑŠÐµÐºÑ‚Ñ‹ Ð² Ñ€Ð°Ð´Ð¸ÑƒÑÐµ Ð´Ð¾ 300Ð¼ (5-7 Ð¼Ð¸Ð½ÑƒÑ‚ Ð¿ÐµÑˆÐºÐ¾Ð¼)\n"
                    "2. Ð”Ð¾Ð¿ÑƒÑÑ‚Ð¸Ð¼Ð¾: Ð´Ð¾ 500-700Ð¼ (10-12 Ð¼Ð¸Ð½ÑƒÑ‚ Ð¿ÐµÑˆÐºÐ¾Ð¼)\n"
                    "3. ÐœÐÐšÐ¡Ð˜ÐœÐ£Ðœ: Ð´Ð¾ 1ÐºÐ¼ (15 Ð¼Ð¸Ð½ÑƒÑ‚ Ð¿ÐµÑˆÐºÐ¾Ð¼)\n"
                    "4. Ð’ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… Ð³Ð¾Ñ€Ð¾Ð´Ð°Ñ… Ð²ÑÐµÐ³Ð´Ð° ÐµÑÑ‚ÑŒ Ñ‡Ñ‚Ð¾-Ñ‚Ð¾ Ñ€ÑÐ´Ð¾Ð¼!\n\n"
                    "ðŸš« ÐÐ• Ð’Ð«Ð‘Ð˜Ð ÐÐ™Ð¢Ð• Ð´Ð°Ð»Ñ‘ÐºÐ¸Ðµ Ð´Ð¾ÑÑ‚Ð¾Ð¿Ñ€Ð¸Ð¼ÐµÑ‡Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸!\n\n"
                    "âš ï¸ ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐ˜ Ð’ÐÐ–ÐÐž - Ð”ÐžÐ¡Ð¢ÐžÐ’Ð•Ð ÐÐžÐ¡Ð¢Ð¬:\n"
                    "â€¢ Ð¢ÐžÐ›Ð¬ÐšÐž Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ðµ Ð¼ÐµÑÑ‚Ð° Ð¸ Ð·Ð´Ð°Ð½Ð¸Ñ\n"
                    "â€¢ Ð¢ÐžÐ›Ð¬ÐšÐž Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐµÐ½Ð½Ñ‹Ðµ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ñ„Ð°ÐºÑ‚Ñ‹ Ð¸Ð· Ð²Ð°ÑˆÐµÐ³Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ\n"
                    "â€¢ ÐÐ• Ð’Ð«Ð”Ð£ÐœÐ«Ð’ÐÐ™Ð¢Ð• Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ñ Ð·Ð´Ð°Ð½Ð¸Ð¹, Ð´Ð°Ñ‚Ñ‹, Ð¸Ð¼ÐµÐ½Ð°, ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ\n"
                    "â€¢ Ð•ÑÐ»Ð¸ Ð½Ðµ Ð·Ð½Ð°ÐµÑ‚Ðµ Ñ‚Ð¾Ñ‡Ð½Ð¾ â€” Ð»ÑƒÑ‡ÑˆÐµ ÑÐºÐ°Ð¶Ð¸Ñ‚Ðµ 'Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð½ÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾'\n"
                    "â€¢ ÐŸÐ ÐžÐ’Ð•Ð Ð¬Ð¢Ð• ÐºÐ°Ð¶Ð´ÑƒÑŽ Ð´ÐµÑ‚Ð°Ð»ÑŒ Ð¿ÐµÑ€ÐµÐ´ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð¼\n\n"
                    "Ð’ÐÐ–ÐÐž: Ð¤Ð°ÐºÑ‚ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð±Ñ‹Ñ‚ÑŒ ÐšÐ ÐÐ¢ÐšÐ˜Ðœ (60-80 ÑÐ»Ð¾Ð²) Ð½Ð¾ Ð”ÐžÐ¡Ð¢ÐžÐ’Ð•Ð ÐÐ«Ðœ. Ð’ÐºÐ»ÑŽÑ‡Ð¸Ñ‚Ðµ Ñ‚Ð¾Ð»ÑŒÐºÐ¾:\n"
                    "- ÐŸÑ€Ð¾Ð²ÐµÑ€ÐµÐ½Ð½ÑƒÑŽ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ñ‡ÐµÑÐºÑƒÑŽ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ\n"
                    "- Ð¢Ð¾Ñ‡Ð½Ñ‹Ðµ Ð´ÐµÑ‚Ð°Ð»Ð¸ Ð¸Ð»Ð¸ Ð´Ð°Ñ‚Ñ‹ (ÐµÑÐ»Ð¸ ÑƒÐ²ÐµÑ€ÐµÐ½Ñ‹)\n"
                    "- Ð”Ð¾ÑÑ‚Ð¾Ð²ÐµÑ€Ð½Ñ‹Ðµ Ð¾ÑÐ¾Ð±ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸ Ð¼ÐµÑÑ‚Ð°\n\n"
                    "Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚ Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ:\n"
                    "Ð›Ð¾ÐºÐ°Ñ†Ð¸Ñ: [ÐšÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð¾Ðµ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ Ð¼ÐµÑÑ‚Ð°]\n"
                    "ÐŸÐ¾Ð¸ÑÐº: [ÐšÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð° Ð´Ð»Ñ Ñ‚Ð¾Ñ‡Ð½Ð¾Ð³Ð¾ Ð¿Ð¾Ð¸ÑÐºÐ°: ÐžÐ Ð˜Ð“Ð˜ÐÐÐ›Ð¬ÐÐžÐ• Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ Ð½Ð° Ð¼ÐµÑÑ‚Ð½Ð¾Ð¼ ÑÐ·Ñ‹ÐºÐµ + Ð³Ð¾Ñ€Ð¾Ð´ + ÑÑ‚Ñ€Ð°Ð½Ð°. ÐÐ°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: 'Louvre Museum Paris France' Ð¸Ð»Ð¸ 'ÐšÑ€Ð°ÑÐ½Ð°Ñ Ð¿Ð»Ð¾Ñ‰Ð°Ð´ÑŒ ÐœÐ¾ÑÐºÐ²Ð° Ð Ð¾ÑÑÐ¸Ñ']\n"
                    "Ð˜Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ñ‹Ð¹ Ñ„Ð°ÐºÑ‚: [ÐšÑ€Ð°Ñ‚ÐºÐ¸Ð¹, Ð½Ð¾ Ð´Ð¾ÑÑ‚Ð¾Ð²ÐµÑ€Ð½Ñ‹Ð¹ Ñ„Ð°ÐºÑ‚, 60-80 ÑÐ»Ð¾Ð²]"
                )

            # Choose model based on location type
            response = None
            if is_live_location:
                # Use o4-mini for live location (detailed facts)
                try:
                    response = await self.client.chat.completions.create(
                        model="o4-mini",
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt},
                        ],
                        max_completion_tokens=10000,  # Large limit for o4-mini extensive reasoning + detailed response
                    )
                    logger.info(f"o4-mini (live location) response: {response}")
                    content = (
                        response.choices[0].message.content
                        if response.choices
                        else None
                    )

                    if not content:
                        logger.warning(
                            "o4-mini returned empty content, falling back to gpt-4.1"
                        )
                        raise ValueError("Empty content from o4-mini")

                except Exception as e:
                    logger.warning(
                        f"o4-mini failed ({e}), falling back to gpt-4.1 for live location"
                    )
                    response = await self.client.chat.completions.create(
                        model="gpt-4.1",
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt},
                        ],
                        max_tokens=800,
                        temperature=0.7,
                    )
                    logger.info(f"gpt-4.1 fallback for live location: {response}")
                    content = (
                        response.choices[0].message.content
                        if response.choices
                        else None
                    )
            else:
                # Use gpt-4.1 for static location (fast, concise facts)
                try:
                    response = await self.client.chat.completions.create(
                        model="gpt-4.1",
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt},
                        ],
                        max_tokens=400,  # Smaller limit for concise facts
                        temperature=0.7,
                    )
                    logger.info(f"gpt-4.1 (static location) response: {response}")
                    content = (
                        response.choices[0].message.content
                        if response.choices
                        else None
                    )

                    if not content:
                        logger.warning(
                            "gpt-4.1 returned empty content for static location"
                        )
                        raise ValueError("Empty content from gpt-4.1")

                except Exception as e:
                    logger.error(f"gpt-4.1 failed for static location: {e}")
                    raise

            if not content:
                logger.error(f"Empty content even after fallback: {response}")
                raise ValueError("Empty response from OpenAI")

            logger.info(f"Generated fact for location {lat},{lon}")
            return content.strip()

        except Exception as e:
            logger.error(f"Failed to generate fact for {lat},{lon}: {e}")
            raise

    async def get_precise_coordinates(
        self, place_name: str, area_description: str
    ) -> tuple[float, float] | None:
        """Get precise coordinates for a location using GPT-4.1 with web search.

        Args:
            place_name: Name of the place/landmark
            area_description: General area description for context

        Returns:
            Tuple of (latitude, longitude) if found, None otherwise
        """
        try:

            # WebSearch tool is deprecated and no longer works
            logger.warning("WebSearch tool is deprecated, skipping web search")
            return None

        except Exception as e:
            logger.error(f"Failed to get precise coordinates for {place_name}: {e}")
            return None

    async def get_coordinates_from_nominatim(
        self, place_name: str
    ) -> tuple[float, float] | None:
        """Get coordinates using OpenStreetMap Nominatim service as fallback.

        Args:
            place_name: Name of the place to search

        Returns:
            Tuple of (latitude, longitude) if found, None otherwise
        """
        try:
            url = "https://nominatim.openstreetmap.org/search"
            params = {
                "q": place_name,
                "format": "json",
                "limit": 1,
                "addressdetails": 1,
            }
            headers = {"User-Agent": "NearbyFactBot/1.0 (Educational Project)"}

            async with aiohttp.ClientSession() as session:
                async with session.get(
                    url, params=params, headers=headers, timeout=5
                ) as response:
                    if response.status == 200:
                        data = await response.json()
                        if data:
                            lat = float(data[0]["lat"])
                            lon = float(data[0]["lon"])

                            if -90 <= lat <= 90 and -180 <= lon <= 180:
                                logger.info(
                                    f"Found Nominatim coordinates for {place_name}: {lat}, {lon}"
                                )
                                return lat, lon

            logger.debug(f"No coordinates found in Nominatim for: {place_name}")
            return None

        except Exception as e:
            logger.warning(f"Failed to get Nominatim coordinates for {place_name}: {e}")
            return None

    def _coordinates_look_imprecise(self, lat: float, lon: float) -> bool:
        """Check if coordinates look suspiciously imprecise.

        Args:
            lat: Latitude
            lon: Longitude

        Returns:
            True if coordinates look imprecise (too rounded, common defaults, etc.)
        """
        # Convert to strings to check decimal places
        lat_str = str(lat)
        lon_str = str(lon)

        # Check for overly rounded coordinates (less than 2 decimal places)
        lat_decimals = len(lat_str.split('.')[-1]) if '.' in lat_str else 0
        lon_decimals = len(lon_str.split('.')[-1]) if '.' in lon_str else 0

        if lat_decimals < 2 or lon_decimals < 2:
            logger.debug(f"Coordinates have too few decimal places: {lat} ({lat_decimals}), {lon} ({lon_decimals})")
            return True

        # Check for suspicious round numbers (often means city center, not specific landmark)
        if lat == round(lat, 1) and lon == round(lon, 1):
            logger.debug(f"Coordinates are suspiciously round: {lat}, {lon}")
            return True

        # Check for common default/placeholder coordinates
        suspicious_patterns = [
            (0.0, 0.0),  # Null Island
            (55.7558, 37.6173),  # Generic Moscow center
            (55.75, 37.62),  # Rounded Moscow
            (59.9311, 30.3609),  # Generic SPb center
        ]

        for sus_lat, sus_lon in suspicious_patterns:
            if abs(lat - sus_lat) < 0.01 and abs(lon - sus_lon) < 0.01:
                logger.debug(f"Coordinates match suspicious pattern: {lat}, {lon}")
                return True

        return False

    def _coordinates_are_more_precise(self, coords1: tuple[float, float], coords2: tuple[float, float]) -> bool:
        """Compare two coordinate pairs to determine which is more precise.

        Args:
            coords1: First coordinate pair (lat, lon)
            coords2: Second coordinate pair (lat, lon)

        Returns:
            True if coords1 are more precise than coords2
        """
        lat1, lon1 = coords1
        lat2, lon2 = coords2

        # Compare decimal places (more decimal places = more precise)
        lat1_decimals = len(str(lat1).split('.')[-1]) if '.' in str(lat1) else 0
        lon1_decimals = len(str(lon1).split('.')[-1]) if '.' in str(lon1) else 0
        lat2_decimals = len(str(lat2).split('.')[-1]) if '.' in str(lat2) else 0
        lon2_decimals = len(str(lon2).split('.')[-1]) if '.' in str(lon2) else 0

        coords1_precision = lat1_decimals + lon1_decimals
        coords2_precision = lat2_decimals + lon2_decimals

        return coords1_precision > coords2_precision

    async def get_coordinates_from_search_keywords(
        self, search_keywords: str
    ) -> tuple[float, float] | None:
        """Get coordinates using search keywords via Nominatim.

        Args:
            search_keywords: Search keywords from GPT response

        Returns:
            Tuple of (latitude, longitude) if found, None otherwise
        """
        logger.info(f"Searching coordinates for keywords: {search_keywords}")

        # Try Nominatim first (faster and often more accurate for landmarks)
        nominatim_coords = await self.get_coordinates_from_nominatim(search_keywords)
        if nominatim_coords:
            logger.info(f"Found Nominatim coordinates: {nominatim_coords}")
            return nominatim_coords

        # Try variations of search keywords if Nominatim fails
        logger.info(f"Nominatim failed for: {search_keywords}")

        # Try simpler search - just the main place name
        if " + " in search_keywords or "+" in search_keywords:
            # Extract first part before + sign
            simple_keywords = search_keywords.split("+")[0].strip()
            logger.info(f"Trying simplified search: {simple_keywords}")
            simple_coords = await self.get_coordinates_from_nominatim(simple_keywords)
            if simple_coords:
                logger.info(f"Found coordinates with simplified search: {simple_coords}")
                return simple_coords

        logger.warning(f"No coordinates found for keywords: {search_keywords}")
        return None

    async def parse_coordinates_from_response(
        self, response: str
    ) -> tuple[float, float] | None:
        """Parse coordinates from OpenAI response using search keywords.

        Args:
            response: OpenAI response text

        Returns:
            Tuple of (latitude, longitude) if found, None otherwise
        """
        try:
            # First, try to extract search keywords from new format
            search_match = re.search(r"ÐŸÐ¾Ð¸ÑÐº:\s*(.+?)(?:\n|$)", response)
            if search_match:
                search_keywords = search_match.group(1).strip()
                logger.info(f"Found search keywords: {search_keywords}")

                # Use new keyword-based search
                coords = await self.get_coordinates_from_search_keywords(search_keywords)
                if coords:
                    return coords

            # Fallback: try to extract location name if no search keywords
            place_match = re.search(r"Ð›Ð¾ÐºÐ°Ñ†Ð¸Ñ:\s*(.+?)(?:\n|$)", response)
            if place_match:
                place_name = place_match.group(1).strip()
                logger.info(f"No search keywords found, using location name: {place_name}")

                # Use location name as search keywords
                coords = await self.get_coordinates_from_search_keywords(place_name)
                if coords:
                    return coords

            logger.debug("No search keywords or location name found in response")
            return None

        except (ValueError, AttributeError) as e:
            logger.warning(f"Error parsing coordinates: {e}")
            return None


# Global client instance - will be initialized lazily
_openai_client: OpenAIClient | None = None


def get_openai_client() -> OpenAIClient:
    """Get or create the global OpenAI client instance."""
    global _openai_client
    if _openai_client is None:
        _openai_client = OpenAIClient()
    return _openai_client
